{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import json\n",
    "import math\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"finalData.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from a5\n",
    "def build_vectorizer():\n",
    "    \"\"\"Returns a TfidfVectorizer object with certain preprocessing properties.\n",
    "    \n",
    "    Params: {max_n_terms: Integer,\n",
    "             max_prop_docs: Float,\n",
    "             min_n_docs: Integer}\n",
    "    Returns: TfidfVectorizer\n",
    "    \"\"\"\n",
    "    return TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from class demo\n",
    "word_splitter = re.compile(r\"\"\"\n",
    "    (\\w+)\n",
    "    \"\"\", re.VERBOSE)\n",
    "\n",
    "def getwords(sent):\n",
    "    return [w.lower() \n",
    "            for w in word_splitter.findall(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = build_vectorizer()\n",
    "stemmer=PorterStemmer()\n",
    "reviews = []\n",
    "for city, city_dic in data.items():\n",
    "    for restaurant, restaurant_dic in city_dic.items():\n",
    "        for review in restaurant_dic['reviews']:\n",
    "            all_words = getwords(review['text'])\n",
    "            stem_text = [stemmer.stem(t.lower()) for t in all_words]\n",
    "            reviews.append(\" \".join(stem_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat = tfidf_vec.fit_transform(reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_mat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tfidf_vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from a5\n",
    "def build_movie_sims_cos(start, end, cos_sim, input_doc_mat, num_movies, norms):\n",
    "    \"\"\"Returns a matrix of size num_movies x num_movies where for (i,j), entry [i,j]\n",
    "       should be the cosine similarity between the movie with index i and the movie with index j\n",
    "        \n",
    "    Note: All movies are trivially perfectly similar to themselves, so the diagonals of the output matrix should be 1.\n",
    "    \n",
    "    Params: {num_movies: Integer,\n",
    "             input_doc_mat: Numpy Array,\n",
    "             movie_index_to_name: Dict,\n",
    "             movie_name_to_index: Dict,\n",
    "             input_get_sim_method: Function}\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "    #cos_sim = np.zeros((num_movies, num_movies))\n",
    "    for i in range(start, end):\n",
    "        if i >= num_movies:\n",
    "            break\n",
    "        for j in range(start, end):\n",
    "            if j >= num_movies:\n",
    "                break\n",
    "            cos_sim[i][j] = np.dot(input_doc_mat[i], input_doc_mat[j])/(norms[i] * norms[j])\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sims_cos = build_movie_sims_cos(len(reviews), tfidf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = np.zeros((len(reviews), len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 5000\n",
    "norms = np.linalg.norm(tfidf_mat, axis=1)\n",
    "last_round = False\n",
    "finished = False\n",
    "while not finished:\n",
    "    print(\"start of loop\")\n",
    "    cos_sim = build_sim_movies(start, end, cos_sim, tfidf_mat, len(reviews), norms)\n",
    "    start += 5001\n",
    "    end += 5001\n",
    "    if end > len(reviews) - 1:\n",
    "        end = len(reviews) - 1\n",
    "        if last_round:\n",
    "            finished = True\n",
    "        last_round = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
