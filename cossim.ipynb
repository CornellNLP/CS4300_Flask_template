{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Pegah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# the imports used in A2\n",
    "import re\n",
    "# import json\n",
    "from glob import glob\n",
    "import os\n",
    "from io import StringIO\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import bs4\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Imports that might help with various functionality\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "# Additional imports from A3\n",
    "from __future__ import print_function\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import Levenshtein  # package python-Levenshtein\n",
    "\n",
    "# Additional imports from A5\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Ensure that your kernel is using Python3\n",
    "assert sys.version_info.major == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1378 women\n",
      "Each woman's entry is a dictionary with the following keys...\n",
      "dict_keys(['name', 'summary'])\n"
     ]
    }
   ],
   "source": [
    "# import the json\n",
    "import json\n",
    "with open(\"updated_data.json\", \"r\") as f:\n",
    "    women_summaries = json.load(f)\n",
    "    \n",
    "# PEGAH (From A5)\n",
    "num_women = len(women_summaries)\n",
    "print(\"Loaded {} women\".format(num_women))\n",
    "print(\"Each woman's entry is a dictionary with the following keys...\")\n",
    "print(women_summaries[0].keys())\n",
    "\n",
    "# print(len(women_summaries))\n",
    "# print(women_summaries)\n",
    "# print(women_summaries[0]['name'])\n",
    "# print(women_summaries[0]['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning an index for each woman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEGAH\n",
    "# Here, we will assign an index for each woman. This index will help us access data in numpy matrices.\n",
    "# woman_to_index = movie_id_to_index\n",
    "woman_to_index = {woman:index for index, woman in enumerate([d[\"name\"] for d in women_summaries])}\n",
    "\n",
    "\n",
    "# and because it might be useful...\n",
    "woman_name_to_index = {name:woman_to_index[name] for name in [d['name'] for d in women_summaries]}\n",
    "woman_index_to_name = {v:k for k,v in woman_name_to_index.items()}\n",
    "\n",
    "# print(\"The index of \\\"{}\\\" is {}\".format(women_summaries[7]['name'], woman_name_to_index[women_summaries[7]['name']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 5000 # QUESTION: What does this do?\n",
    "doc_by_vocab = np.empty([len(women_summaries), n_feats])\n",
    "\n",
    "def build_vectorizer(max_features, stop_words, max_df=0.8, min_df=10, norm='l2'):\n",
    "    \"\"\"Returns a TfidfVectorizer object\n",
    "    \n",
    "    Params: {max_features: Integer,\n",
    "             max_df: Float,\n",
    "             min_df: Float,\n",
    "             norm: String,\n",
    "             stop_words: String}\n",
    "    Returns: TfidfVectorizer\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return TfidfVectorizer(stop_words=stop_words, max_features=max_features, max_df=max_df, min_df=min_df, norm=norm)\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "tfidf_vec = build_vectorizer(n_feats, \"english\")\n",
    "doc_by_vocab = tfidf_vec.fit_transform([d['summary'] for d in women_summaries]).toarray()\n",
    "index_to_vocab = {i:v for i, v in enumerate(tfidf_vec.get_feature_names())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(wom1, wom2, input_doc_mat, woman_name_to_index):\n",
    "    \"\"\"Returns a float giving the cosine similarity of \n",
    "       the two movie transcripts.\n",
    "    \n",
    "    Params: {mov1: String,\n",
    "             mov2: String,\n",
    "             input_doc_mat: Numpy Array,\n",
    "             movie_name_to_index: Dict}\n",
    "    Returns: Float (Cosine similarity of the two movie transcripts.)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    a = input_doc_mat[woman_name_to_index[wom1]] #this gives us the [......] freq of all words\n",
    "    b = input_doc_mat[woman_name_to_index[wom2]] \n",
    "    return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: Mary Anning vs. Lilias Armstrong\n",
      "======\n",
      "0.14088923737130635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check that get_sim returns the correct output\"\"\"\n",
    "print(\"Similarity: Mary Anning vs. Lilias Armstrong\")\n",
    "print(\"======\")\n",
    "test1 = get_sim('Lilias Armstrong', 'Mary Anning', doc_by_vocab, woman_name_to_index)\n",
    "print(test1)\n",
    "assert test1 < 1 and test1 > 0\n",
    "print(\"\")\n",
    "\n",
    "# print(\"Similarity: Star Wars vs. Star Trek: Generations\")\n",
    "# print(\"======\")\n",
    "# test2 = get_sim('star wars', 'star trek: generations', doc_by_vocab, movie_name_to_index)\n",
    "# print(test2)\n",
    "# assert test2 < 0.25 and test2 > 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_woman_sims_cos(n_wom, woman_index_to_name,input_doc_mat,woman_name_to_index,input_get_sim_method):\n",
    "    \"\"\"Returns a movie_sims matrix of size (num_movies,num_movies) where for (i,j):\n",
    "        [i,j] should be the cosine similarity between the movie with index i and the movie with index j\n",
    "        \n",
    "    Note: What you set the diagonal to doesn't really matter, \n",
    "    but you should set it to 1 to indicate that all movies are trivially perfectly similar to themselves.\n",
    "    \n",
    "    Params: {n_mov: Integer,\n",
    "             movie_index_to_name: String,\n",
    "             input_doc_mat: Numpy Array,\n",
    "             movie_name_to_index: Dict,\n",
    "             input_get_sim_method: Function}\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "    \n",
    "    woman_sims = np.ones((n_wom, n_wom)) #instantiate array\n",
    "    for i in range(0, n_wom):\n",
    "        for j in range(0, n_wom):\n",
    "            woman_sims[i,j] = input_get_sim_method(woman_index_to_name[i], woman_index_to_name[j], input_doc_mat, woman_name_to_index)\n",
    "    return woman_sims\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-f6688cd3a8be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwoman_sims_cos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_woman_sims_cos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_women\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwoman_index_to_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_by_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwoman_name_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-26556d6fa71c>\u001b[0m in \u001b[0;36mbuild_woman_sims_cos\u001b[0;34m(n_wom, woman_index_to_name, input_doc_mat, woman_name_to_index, input_get_sim_method)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_wom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_wom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mwoman_sims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_get_sim_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwoman_index_to_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwoman_index_to_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_doc_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwoman_name_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwoman_sims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "woman_sims_cos = build_woman_sims_cos(num_women, woman_index_to_name, doc_by_vocab, woman_name_to_index, get_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
