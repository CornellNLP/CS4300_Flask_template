{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize (text): \n",
    "    return (re.findall ('[a-z]+', text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"steep hills, big mountain, fast runs, dangerous runs, thrill seeker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('ski_reviews.csv', header= 1)\n",
    "    dataframe = pd.DataFrame (df)\n",
    "    nump_data = dataframe.to_numpy()\n",
    "\n",
    "    dict_ski = {}\n",
    "    num_states = 0 \n",
    "    num_locs = 0\n",
    "    for data in nump_data :\n",
    "        state = str(data[1])\n",
    "        ski_area = str(data[2])\n",
    "        reviewer = str(data[3])\n",
    "        date = data[4]\n",
    "        rating = data[5]\n",
    "        review = str(data[6])\n",
    "    \n",
    "        if state in dict_ski:\n",
    "            if ski_area in dict_ski[state]: \n",
    "                dict_ski[state][ski_area].append((date, reviewer, rating, review))\n",
    "            else: \n",
    "                dict_ski[state][ski_area] = [(date, reviewer, rating, review)] \n",
    "                num_locs += 1 \n",
    "        else: \n",
    "            num_states += 1 \n",
    "            num_locs += 1\n",
    "            dict_ski[state] = {ski_area: [(date, reviewer, rating, review)]}\n",
    "            \n",
    "    return dict_ski "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ski = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vectorizer(max_n_terms=5000, max_prop_docs=0.8, min_n_docs=10):\n",
    "    \"\"\"Returns a TfidfVectorizer object with certain preprocessing properties.\n",
    "    \n",
    "    Params: {max_n_terms: Integer,\n",
    "             max_prop_docs: Float,\n",
    "             min_n_docs: Integer}\n",
    "    Returns: TfidfVectorizer\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(min_df = min_n_docs, max_df = max_prop_docs, max_features = max_n_terms, stop_words = \"english\")\n",
    "    return vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_vectorize(query ,dict_ski,vectorizer = build_vectorizer(max_n_terms=5000, max_prop_docs=0.8, min_n_docs=10)):\n",
    "    state_locs =  list(dict_ski.values())\n",
    "    state_names = list (dict_ski.keys())\n",
    "    location_names = []\n",
    "    reviews_by_loc = [('query',query)]\n",
    "\n",
    "    for loc in state_locs: \n",
    "        location_names.extend(list(loc.keys()))\n",
    "        for site in loc: \n",
    "            site_revs = []\n",
    "            site_str = \" \"\n",
    "            site_revs.extend([tup[3] for tup in loc[site]])\n",
    "            reviews_by_loc.append((site, site_str.join(site_revs)))\n",
    "    return reviews_by_loc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_by_loc = vectorize(query, dict_ski)\n",
    "num_locs = len (reviews_by_loc)\n",
    "\n",
    "ski_site_to_index = {site:index for index, site in enumerate([site[0] for site in reviews_by_loc])}\n",
    "ski_index_to_site = {index:site for index, site in enumerate([site[0] for site in reviews_by_loc])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = build_vectorizer()\n",
    "tfidf_mat = tfidf_vec.fit_transform([site[1] for site in reviews_by_loc]).toarray()\n",
    "index_to_vocab = {i:v for i, v in enumerate(tfidf_vec.get_feature_names())}\n",
    "vocab_to_index = {v:i for i, v in enumerate(tfidf_vec.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(loc1, loc2, input_mat, \n",
    "                site_to_index=ski_site_to_index):\n",
    "    \"\"\"Returns the cosine similarity of reviews from two locations \n",
    "    \"\"\"\n",
    "    loc1_tf = input_mat[site_to_index[loc1]]\n",
    "    loc2_tf = input_mat[site_to_index[loc2]]\n",
    "    cossim = np.dot(loc1_tf, loc2_tf)/ (np.linalg.norm(loc1_tf) * np.linalg.norm(loc2_tf))\n",
    "    \n",
    "    return cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sims_cos(input_doc_mat):\n",
    "    \"\"\"Returns a matrix of size num_movies x num_movies where for (i,j), entry [i,j]\n",
    "       should be the cosine similarity between the movie with index i and the movie with index j\n",
    "        \n",
    "    Note: All movies are trivially perfectly similar to themselves, so the diagonals of the output matrix should be 1.\n",
    "    \n",
    "    Params: {num_movies: Integer,\n",
    "             input_doc_mat: Numpy Array,\n",
    "             movie_index_to_name: Dict,\n",
    "             movie_name_to_index: Dict,\n",
    "             input_get_sim_method: Function}\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "\n",
    "    trans_input = np.transpose(input_doc_mat)\n",
    "    numer = np.dot(input_doc_mat, trans_input)\n",
    "    denom = np.linalg.norm(input_doc_mat, axis = 1)\n",
    "    denom_new = denom[:, np.newaxis]\n",
    "    denom_final = np.multiply (denom, denom_new) \n",
    "    fin = np.divide(numer,denom_final)\n",
    "    \n",
    "    return fin \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1256322735230599, 'ski-brule'), (0.08647190464549602, 'cannonsburg'), (0.08448737920112143, 'mount-kato-ski-area'), (0.08373349131968721, 'sunburst')]\n"
     ]
    }
   ],
   "source": [
    "def most_sim (tdif_mat): \n",
    "    sim_mat = build_sims_cos(tfidf_mat)\n",
    "    most_sim = sim_mat[0]\n",
    "    sim = []\n",
    "    count = 0\n",
    "    for i in most_sim: \n",
    "        sim.append((i,ski_index_to_site[count]))\n",
    "        count += 1\n",
    "    \n",
    "    x = sorted(sim, key=lambda x: x[0], reverse=True)\n",
    "    top_3_rankings = x[1:5]\n",
    "\n",
    "    return top_3_rankings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
